# Architecture Documentation

This document explains the technical decisions, design patterns, and architectural choices made in building the Document Analysis Platform.

## Table of Contents

1. [System Overview](#system-overview)
2. [Technology Choices](#technology-choices)
3. [Data Architecture](#data-architecture)
4. [API Design](#api-design)
5. [State Management](#state-management)
6. [Real-Time Communication](#real-time-communication)
7. [Queue Management](#queue-management)
8. [Error Handling](#error-handling)
9. [Performance Optimizations](#performance-optimizations)
10. [Security Considerations](#security-considerations)
11. [Scalability](#scalability)

---

## System Overview

The application follows a client-server architecture with real-time communication via Server-Sent Events (SSE).

```
┌─────────────────┐
│   Browser       │
│  (React/Next)   │
└────────┬────────┘
         │ HTTP/SSE
         │
┌────────▼────────┐
│  Next.js API    │
│   (Node.js)     │
└────────┬────────┘
         │
    ┌────┴────┬──────────┐
    │         │          │
┌───▼───┐ ┌──▼───┐ ┌────▼─────┐
│  JSON │ │Queue │ │Hugging   │
│  DB   │ │System│ │Face API  │
└───────┘ └──────┘ └──────────┘
```

---

## Technology Choices

### Next.js 15 (App Router)

**Why Next.js?**

- Server-Side Rendering (SSR) capabilities
- API routes co-located with frontend
- Built-in routing with file-based system
- Excellent TypeScript support
- Image and font optimization out of the box

**Why App Router over Pages Router?**

- Modern React Server Components
- Better data fetching patterns
- Streaming and Suspense support
- Simpler layouts and error boundaries
- Future-proof (recommended by Next.js team)

### TypeScript (Strict Mode)

**Benefits:**

- Catch errors at compile time
- Better IDE autocomplete
- Self-documenting code
- Easier refactoring
- Type safety across client and server

**Strict mode enabled to:**

- Prevent `any` type usage
- Enforce null checks
- Require explicit return types on functions

### Tailwind CSS v4

**Why Tailwind?**

- Utility-first approach reduces CSS bundle size
- Consistent design system
- Dark mode built-in with `dark:` variant
- Responsive design with mobile-first breakpoints
- No CSS naming conflicts

**V4 advantages:**

- Simpler configuration with `@import 'tailwindcss'`
- Better performance
- Smaller bundle size

---

## Data Architecture

### JSON File Storage

**Decision:** Use JSON file instead of database

**Rationale:**

- Assessment doesn't require database
- Simpler setup for evaluators
- Fast read/write operations for small datasets
- Git-friendly (sample data in repo)

**Trade-offs:**

- ✅ Simple, no setup required
- ✅ Fast for small datasets (<1000 documents)
- ❌ Not suitable for production
- ❌ No concurrent write protection
- ❌ Not horizontally scalable

**Production Alternative:**

```typescript
// Would use PostgreSQL + Prisma:
const documents = await prisma.document.findMany({
  where: { userId: session.user.id },
  orderBy: { createdAt: 'desc' },
});
```

### Document Schema

```typescript
interface Document {
  id: string; // UUID for uniqueness
  title: string; // User-provided or auto-generated
  content: string; // Full document text
  createdAt: string; // ISO timestamp
  status: 'idle' | 'processing' | 'completed' | 'failed';
  summary: string | null; // Generated by AI
  sentiment: {
    // Generated by AI
    label: string;
    score: number;
  } | null;
  entities:
    | {
        // Generated by AI
        type: string;
        value: string;
      }[]
    | null;
}
```

**Why `| null` instead of `?` optional:**

- Explicit presence in JSON (property always exists)
- Easier to serialize/deserialize
- No ambiguity between "missing" and "null"

---

## API Design

### RESTful Endpoints

```
GET    /api/documents           # List all documents
POST   /api/documents           # Create new document
GET    /api/documents/[id]      # Get single document
PATCH  /api/documents/[id]      # Update document (title)
DELETE /api/documents/[id]      # Delete document
POST   /api/documents/analyze   # Start analysis (SSE)
GET    /api/documents/analyze   # Get queue status
```

### Why PATCH over PUT?

**PATCH** = Partial update (only send changed fields)
**PUT** = Full replacement (send entire object)

```typescript
// PATCH /api/documents/[id]
{ "title": "New Title" }  // Only update title

// PUT would require:
{
  "id": "...",
  "title": "New Title",
  "content": "...",
  // ... all fields required
}
```

---

## State Management

### Choice: React Hooks (No Redux/Zustand)

**Rationale:**

- Application state is relatively simple
- Most state is local to components
- Prop drilling is minimal (2-3 levels max)
- Hooks provide sufficient functionality

**State Organization:**

```typescript
// Global state (HomePage)
- documents: Document[]
- filters: { search, status, dateRange, sort }

// Local state (DocumentItem)
- isEditing: boolean
- showDeleteConfirm: boolean

// Shared via props
- onUpdate: () => void  // Callback to refetch
```

### Why useMemo for Filtering?

```typescript
const filteredDocs = useMemo(() => {
  // Expensive operations:
  // - Filter 100+ documents
  // - String comparisons (search)
  // - Date comparisons
  // - Sorting
  return documents.filter(...).sort(...)
}, [documents, searchQuery, filters])
```

**Without useMemo:**

- Runs on EVERY render
- Wasted CPU on unchanged data

**With useMemo:**

- Only runs when dependencies change
- Caches result for reuse

---

## Real-Time Communication

### Server-Sent Events (SSE) vs WebSocket

**Why SSE?**

| Feature      | SSE             | WebSocket      |
| ------------ | --------------- | -------------- |
| Direction    | Server → Client | Bi-directional |
| Protocol     | HTTP            | WS protocol    |
| Reconnection | Automatic       | Manual         |
| Complexity   | Simple          | Complex        |
| Our Use Case | ✅ Perfect      | ❌ Overkill    |

We only need **server-to-client** streaming (AI results), not client-to-server.

### SSE Implementation

**Server (API Route):**

```typescript
return new ReadableStream({
  async start(controller) {
    const encoder = new TextEncoder()

    // Send progress updates
    controller.enqueue(encoder.encode(
      `data: ${JSON.stringify({ type: 'progress', data: {...} })}\n\n`
    ))

    // Close when done
    controller.close()
  }
})
```

**Client (React Hook):**

```typescript
const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  // Parse SSE format: "data: {...}\n\n"
  const chunk = decoder.decode(value);
  const data = JSON.parse(chunk.slice(6)); // Remove "data: "

  handleEvent(data);
}
```

### Event Types

```typescript
type: 'progress'; // Update progress bar
type: 'summary'; // Display summary result
type: 'sentiment'; // Display sentiment result
type: 'entities'; // Display entities result
type: 'complete'; // Mark as done
type: 'error'; // Show error message
```

---

## Queue Management

### Concurrent Limit: 3

**Why 3?**

- Hugging Face free tier has rate limits
- Each model call takes ~3-10 seconds
- 3 concurrent = good balance of throughput and resource usage
- Prevents overwhelming the API

### Queue Implementation

```typescript
class AnalysisQueue {
  private processing: Set<string>  // Currently running (max 3)
  private queue: QueueItem[]       // Waiting to run

  canProcess(): boolean {
    return this.processing.size < 3
  }

  add(documentId: string): number {
    this.queue.push({ documentId, ... })
    return this.queue.length  // Queue position
  }

  completeProcessing(documentId: string): void {
    this.processing.delete(documentId)
    this.processNext()  // Start next in queue
  }
}
```

### Why Singleton?

```typescript
export const analysisQueue = new AnalysisQueue();
```

- **One global queue** shared across all API routes
- Enforces 3-slot limit globally
- Without singleton: Each route would have separate queue (broken!)

### Production Considerations

Current implementation limitations:

- ❌ Queue resets on server restart
- ❌ Doesn't work with multiple server instances
- ❌ No persistence

**Production solution: Redis**

```typescript
// Would use Redis for distributed queue:
await redis.lpush('analysis_queue', documentId);
await redis.sadd('processing', documentId);
const queueLength = await redis.llen('analysis_queue');
```

---

## Error Handling

### Multi-Layer Strategy

**1. Client-Side Validation**

```typescript
if (!title.trim()) {
  setError('Title is required'); // Instant feedback
  return;
}
```

**2. API Route Validation**

```typescript
if (!body.title) {
  return Response.json({ error: '...' }, { status: 400 });
}
```

**3. Error Boundaries**

```typescript
// app/error.tsx - Catches React errors
// app/documents/[id]/error.tsx - Specific to detail page
```

### Hugging Face API Error Handling

**429 - Rate Limit:**

```typescript
// Exponential backoff: 1s, 2s, 4s
for (let i = 0; i < 3; i++) {
  try {
    return await apiCall();
  } catch (error) {
    if (error.status === 429) {
      await sleep(1000 * Math.pow(2, i));
      continue;
    }
    throw error;
  }
}
```

**503 - Model Loading:**

```typescript
if (status === 503) {
  // Cold start - model not in memory
  throw {
    message: 'Model loading, please wait ~20s',
    estimatedTime: 20,
  };
}
```

**Partial Success:**

```typescript
// Each model wrapped in try-catch
try {
  const summary = await generateSummary();
  sendEvent('summary', { summary });
} catch (error) {
  sendEvent('error', { type: 'summary', message: '...' });
}

// Continue to next model even if this one failed!
```

---

## Performance Optimizations

### 1. Code Splitting

```typescript
const SearchAndFilters = dynamic(
  () => import('@/components/SearchAndFilters'),
  {
    loading: () => <Skeleton />,
    ssr: false,
  }
);
```

**Impact:**

- Reduces initial bundle size
- Lazy loads search UI (not critical for first render)
- Shows skeleton while loading

### 2. React.memo

```typescript
export default memo(DocumentItem);
```

**Prevents re-render when:**

- Parent re-renders
- Props haven't changed
- Saves unnecessary DOM updates

### 3. useCallback

```typescript
const fetchDocuments = useCallback(async () => {
  // ...
}, []); // Function identity stays same across renders
```

**Without useCallback:**

- New function created every render
- Breaks memo() optimization
- Triggers child re-renders

### 4. Debounced Search

```typescript
// User types: "a" "r" "t" "i" "f" "i" "c" "i" "a" "l"
// Without debounce: 10 filter operations
// With 300ms debounce: 1 filter operation (after typing stops)
```

### 5. Skeleton Screens

**Instead of:**

```tsx
{
  loading ? <Spinner /> : <DocumentList />;
}
```

**Use:**

```tsx
<DocumentList loading={loading} />
// Shows skeleton cards during loading
```

**Benefits:**

- Perceived performance improvement
- Layout doesn't shift
- Users see structure immediately

---

## Security Considerations

### 1. API Token Protection

```typescript
// ❌ Never expose token to client
const HF_TOKEN = process.env.HUGGINGFACE_API_TOKEN;

// ✅ All AI calls happen server-side
export async function POST(request: Request) {
  // Token stays on server
  await fetch(HF_API, {
    headers: { Authorization: `Bearer ${HF_TOKEN}` },
  });
}
```

### 2. Input Validation

```typescript
// Sanitize user input
const title = body.title.trim();
const content = body.content.slice(0, 5000); // Enforce limit

// Validate file uploads
if (!file.name.endsWith('.txt')) {
  return error('Invalid file type');
}
if (file.size > 50 * 1024) {
  return error('File too large');
}
```

### 3. XSS Prevention

```tsx
// ❌ Dangerous
<div>{userInput}</div>

// ✅ React escapes by default
<div>{document.title}</div>

// ⚠️ Only use dangerouslySetInnerHTML when YOU control the HTML
<div dangerouslySetInnerHTML={{ __html: getHighlightedText() }} />
// Safe because we generate the HTML ourselves (entity highlighting)
```

### 4. CSRF Protection

Next.js API routes are protected by:

- Same-origin policy
- HTTP-only cookies (if using auth)
- No credentials exposed to client

---

## Scalability

### Current Limitations

**Single Server:**

- JSON file storage
- In-memory queue
- Works for ~100 concurrent users max

### Scaling to 10,000 Users

**Required Changes:**

**1. Database**

```typescript
// PostgreSQL with connection pooling
const documents = await prisma.document.findMany({
  take: 20, // Pagination
  skip: page * 20,
  where: { userId: user.id }, // Per-user data
});
```

**2. Distributed Queue**

```typescript
// Redis for queue management
await redis.lpush(`queue:${userId}`, documentId);
await redis.sadd('global:processing', documentId);
```

**3. Load Balancing**

```
┌──────┐     ┌──────────┐
│Users │────▶│   Load   │
└──────┘     │ Balancer │
             └─────┬────┘
                   │
        ┌──────────┼──────────┐
        │          │          │
    ┌───▼───┐  ┌──▼───┐  ┌──▼───┐
    │Server│  │Server│  │Server│
    │  1   │  │  2   │  │  3   │
    └───┬──┘  └──┬───┘  └──┬───┘
        │        │         │
        └────────┼─────────┘
                 │
         ┌───────▼────────┐
         │   PostgreSQL   │
         │     Redis      │
         └────────────────┘
```

**4. Caching**

```typescript
// Cache document lists
const cachedDocs = await redis.get(`docs:${userId}`);
if (cachedDocs) return JSON.parse(cachedDocs);

const docs = await db.documents.findMany();
await redis.setex(`docs:${userId}`, 300, JSON.stringify(docs));
```

**5. CDN**

- Serve static assets from CDN
- Edge functions for API routes near users
- Reduce latency globally

### Cost Estimate (10,000 Users)

- **Hosting:** Vercel Pro ($20/month)
- **Database:** PostgreSQL on Railway ($10/month)
- **Redis:** Upstash ($10/month)
- **AI API:** Hugging Face Pro ($9/month)
- **Total:** ~$50/month

---

## Conclusion

This architecture prioritizes:

1. **Developer Experience** - Fast iteration, clear structure
2. **User Experience** - Real-time feedback, smooth interactions
3. **Maintainability** - Type safety, clear patterns
4. **Scalability Path** - Clear upgrade path for production

Trade-offs were made appropriate for a technical assessment while documenting production-ready alternatives.

---

**Questions or suggestions?** Feel free to reach out!
